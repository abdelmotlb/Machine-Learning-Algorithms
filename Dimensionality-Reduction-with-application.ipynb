{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdelmotlb/Machine-Learning-Algorithms/blob/main/Dimensionality-Reduction-with-application.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygqMuuXcKsx3"
      },
      "source": [
        "# <font color='orange' size='7px'> ***Global***</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDxI3gRmLAcu"
      },
      "source": [
        "## *Libraries*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17f56ByWLOSX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from google.colab import drive\n",
        "import math\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1ZhUDinLRKv"
      },
      "source": [
        "## *Variables*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp_bSNS_LfpX"
      },
      "outputs": [],
      "source": [
        "numberOfImages = 400\n",
        "ImageWidth = 112\n",
        "ImageHeight = 92\n",
        "maxbrightness = 255\n",
        "numberOfFeatures = ImageWidth * ImageHeight\n",
        "defaultPath = \"/content\"\n",
        "facesPath = \"/content/g\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYQcuv3KLCTx"
      },
      "source": [
        "# <font color='orange' size='7px'> ***Kaggle Data Configuration***</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hold content folder by kaggle\n"
      ],
      "metadata": {
        "id": "aXI8HMGKFxxi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWeTdMVD8Zrv"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqXEzv8NMK8L"
      },
      "source": [
        "##  Faces Landing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp4Hmdz78fUm",
        "outputId": "81295254-1cb0-4853-de96-003be2f2b4c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading att-database-of-faces.zip to /content\n",
            "  0% 0.00/3.61M [00:00<?, ?B/s]\n",
            "100% 3.61M/3.61M [00:00<00:00, 44.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d kasikrit/att-database-of-faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19Dum26bcRkT"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# create faces directory\n",
        "os.mkdir(facesPath)\n",
        "with zipfile.ZipFile(\"att-database-of-faces.zip\", 'r') as zip_ref:\n",
        "  os.chdir(facesPath)\n",
        "  zip_ref.extractall()\n",
        "\n",
        "# reset default unzip directory\n",
        "os.chdir(defaultPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gxj5BQYMWyi"
      },
      "source": [
        "## Import Non-Faces images from Kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgOCK1ggMDlT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "542ae731-6dbb-4ae5-fa59-42db1b928ece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading landscape-image-colorization.zip to /content\n",
            "100% 192M/192M [00:02<00:00, 112MB/s] \n",
            "100% 192M/192M [00:02<00:00, 82.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d theblackmamba31/landscape-image-colorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KU2THTHCMJHD"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"landscape-image-colorization.zip\", 'r') as zip_ref:\n",
        "  zip_ref.extractall()\n",
        "# create a folder to hold all non-face images in\n",
        "\n",
        "parent_dir = \"/content/\"\n",
        "s0_dir = os.path.join(parent_dir, \"s0\")\n",
        "s0s0_dir = os.path.join(s0_dir, \"s0\")\n",
        "# Create the parent directory if it doesn't exist\n",
        "if not os.path.exists(s0_dir):\n",
        "  os.mkdir(s0_dir)\n",
        "# Create the target directory\n",
        "if not os.path.exists(s0s0_dir):\n",
        "  os.mkdir(s0s0_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSJhECMNKOQX"
      },
      "source": [
        "# <font color='orange' size='7px'> ***Dataset Loader***</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eof9VBz0KXKH"
      },
      "source": [
        "## *Image reader*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYSUF2A8Kior"
      },
      "outputs": [],
      "source": [
        "# read specific image.\n",
        "def readImage(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        # Read magic number and skip it\n",
        "        f.readline()\n",
        "        # Read w, h\n",
        "        width, height = map(int, f.readline().split())\n",
        "        maxval = int(f.readline().strip())\n",
        "\n",
        "        # Read pixel data\n",
        "        pixels = [list(f.read(width)) for _ in range(height)]\n",
        "\n",
        "    return width, height, maxval, pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQAB-SBLL5QG"
      },
      "source": [
        "## *Helper Functions*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7pJTN5RL-g-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def getSubject(dirname):\n",
        "    folder_name = os.path.basename(dirname)\n",
        "    ImageSubject = int(folder_name[1:])\n",
        "    return ImageSubject\n",
        "\n",
        "def getCurrentPathOfFile(dirname, filename):\n",
        "    return os.path.join(dirname, filename)\n",
        "\n",
        "def generateColumnsNames():\n",
        "    return ['p' + str(i) for i in range(40)]\n",
        "\n",
        "def formulatedImage(pixels):\n",
        "    return np.array(pixels).reshape(-1)\n",
        "\n",
        "def plot_image(image_array, resized):\n",
        "  '''\n",
        "  parameter: 1d-array, bool value\n",
        "  '''\n",
        "  if resized:\n",
        "    plt.imshow(image_array.reshape(112 // 2, 92 // 2), cmap='gray')  # Use 'cmap=None' if the image is colored\n",
        "  else:\n",
        "    plt.imshow(image_array.reshape(112, 92), cmap='gray')\n",
        "  plt.axis('off')  # Turn off axis\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzG7HGpEMCiP"
      },
      "source": [
        "## *Data Loader*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resize(dataMatrix):\n",
        "  new_data_matrix = np.zeros([numberOfImages, int(numberOfFeatures / 4)])\n",
        "  for image in range(numberOfImages):\n",
        "    count = 0\n",
        "    for row in range(0,ImageHeight,2):\n",
        "      for col in range(0,ImageWidth,2):\n",
        "        new_data_matrix[image][count] = (dataMatrix[image][row*ImageWidth+col] + dataMatrix[image][(row+1)*ImageWidth+col] + dataMatrix[image][row*ImageWidth+col+1] + dataMatrix[image][(row+1)*ImageWidth+col+1])/4\n",
        "        count = count + 1\n",
        "  return new_data_matrix"
      ],
      "metadata": {
        "id": "zVYHebCHAhIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_image(image_array):\n",
        "    plt.imshow(image_array.reshape(112, 92), cmap='gray')  # Use 'cmap=None' if the image is colored\n",
        "    plt.axis('off')  # Turn off axis\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vXhesq4bX4-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCMjCNoCMO7P"
      },
      "outputs": [],
      "source": [
        "import imageio as img\n",
        "\n",
        "def loadDataset(absoluteDirectoryPath):\n",
        "\n",
        "    dataMatrix = np.empty((numberOfImages, numberOfFeatures))\n",
        "    labels = np.empty(numberOfImages)\n",
        "\n",
        "    instanceCounter = 0\n",
        "    for dirname, _, filenames in os.walk(absoluteDirectoryPath):\n",
        "        for filename in sorted(filenames):\n",
        "          file_name, file_extension = os.path.splitext(filename)\n",
        "          if file_extension != \".pgm\":\n",
        "            continue\n",
        "\n",
        "          width, height, maxval, pixels = readImage(getCurrentPathOfFile(dirname, filename))\n",
        "          dataMatrix[instanceCounter] = formulatedImage(pixels)\n",
        "          labels[instanceCounter] = getSubject(dirname)\n",
        "          instanceCounter = instanceCounter + 1\n",
        "\n",
        "    dataMatrix = resize(dataMatrix)\n",
        "    return dataMatrix, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWdb4cyMM2Mw"
      },
      "source": [
        "## Dataset splitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4pgjHMGmo_L"
      },
      "outputs": [],
      "source": [
        "def split_dataset(matrix, labels, train_ratio):\n",
        "  n = math.ceil(1.0/(1-train_ratio))\n",
        "\n",
        "  combined_data = list(zip(matrix, labels))\n",
        "  sorted_data = sorted(combined_data, key=lambda x: x[1])\n",
        "\n",
        "  # Unpack the sorted data into separate matrices\n",
        "  sorted_matrix_2d = np.array([row for row, label in sorted_data])\n",
        "  sorted_labels = np.array([label for row, label in sorted_data])\n",
        "  sorted_matrix_3d = [[] for _ in range(41)]\n",
        "  X_test = []\n",
        "  X_labels = []\n",
        "  y_test = []\n",
        "\n",
        "  for i in range(int(len(sorted_matrix_2d)/10)):\n",
        "    for j in range(10):\n",
        "      if(j % n):\n",
        "        sorted_matrix_3d[int(sorted_labels[i*10+j])].append(sorted_matrix_2d[i*10+j])\n",
        "        y_test.append(int(sorted_labels[i*10+j]))\n",
        "      else:\n",
        "        X_test.append(sorted_matrix_2d[i*10+j])\n",
        "        X_labels.append(int(sorted_labels[i*10+j]))\n",
        "\n",
        "  return sorted_matrix_3d, y_test, X_test, X_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PdiCmpRpP_S"
      },
      "source": [
        "# <font color='orange' size='7px'> ***PCA***</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMWnz4glpXXR"
      },
      "source": [
        "## *Basic*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvrL3HAKM8_l"
      },
      "source": [
        "### PCA sub functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LRwedRGM_qU"
      },
      "outputs": [],
      "source": [
        "def center_data(data_matrix):\n",
        "  data_matrix_mean = np.mean(data_matrix, axis=0)\n",
        "  return data_matrix - data_matrix_mean\n",
        "\n",
        "def sort_eigen_values_and_vectors(eigen_values, eigen_vectors):\n",
        "  sorted_indices = np.argsort(eigen_values)[::-1]\n",
        "  sorted_eigen_values = eigen_values[sorted_indices]\n",
        "  sorted_eigen_vectors = eigen_vectors[:, sorted_indices]\n",
        "  return sorted_eigen_values, sorted_eigen_vectors\n",
        "\n",
        "def choose_r(sorted_eigen_values, alpha):\n",
        "  sum_all_eigen_values = np.sum(sorted_eigen_values)\n",
        "  sum_till_r = 0.0\n",
        "  r = sorted_eigen_values.size\n",
        "  for i in range(sorted_eigen_values.size) :\n",
        "    sum_till_r = sum_till_r + sorted_eigen_values[i]\n",
        "    if sum_till_r / sum_all_eigen_values >= alpha:\n",
        "      r = i\n",
        "      break;\n",
        "  return r + 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP1f8N73NK3N"
      },
      "source": [
        "### PCA main function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5BwNlj2ph34"
      },
      "outputs": [],
      "source": [
        "def calc_eig_vector(data_matrix):\n",
        "  centered_data_matrix = center_data(data_matrix)\n",
        "\n",
        "  cov_matrix = np.cov(centered_data_matrix.T, bias=True)\n",
        "\n",
        "  eigen_values, eigen_vectors = np.linalg.eigh(cov_matrix)\n",
        "\n",
        "  return sort_eigen_values_and_vectors(eigen_values, eigen_vectors)\n",
        "\n",
        "def reduce_dimentions(sorted_eigen_values, sorted_eigen_vectors, alpha):\n",
        "  r = choose_r(sorted_eigen_values, alpha)\n",
        "  return sorted_eigen_vectors[:, :r]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXTE04onNGRN"
      },
      "source": [
        "## After dimentions reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ct6M9QZ_UaIS"
      },
      "outputs": [],
      "source": [
        "def project(basis, data):\n",
        "  ans = np.dot(basis.T, data.T).T\n",
        "  return ans\n",
        "\n",
        "def project_all_data(new_basis, training_data, testinig_data):\n",
        "  new_training_data = project(new_basis, training_data)\n",
        "  new_testinig_data = project(new_basis, testinig_data)\n",
        "  return new_training_data.real, new_testinig_data.real\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nO97mPZFrpXx"
      },
      "outputs": [],
      "source": [
        "def cluster(new_training_data, training_labels, new_testinig_data, testing_labels, num_neigbours=1):\n",
        "  knn_classifier = KNeighborsClassifier(n_neighbors=num_neigbours)\n",
        "  knn_classifier.fit(new_training_data, training_labels)\n",
        "  predictions = knn_classifier.predict(new_testinig_data)\n",
        "  accuracy = accuracy_score(testing_labels, predictions)\n",
        "  report = classification_report(testing_labels, predictions)\n",
        "\n",
        "  print(predictions.shape, testing_labels.shape)\n",
        "\n",
        "  incorrect_indices = [i for i, (true_label, predicted_label) in enumerate(zip(testing_labels, predictions)) if true_label != predicted_label]\n",
        "\n",
        "  print(\"Indices of incorrect predictions:\")\n",
        "  print(incorrect_indices)\n",
        "\n",
        "  return accuracy, report, incorrect_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e_08w8hAC4b"
      },
      "source": [
        "# <font color='orange' size='7px'> ***LDA***</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiGbTtWKAC4c"
      },
      "source": [
        "## *Basic*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysEKwkNLAC4c"
      },
      "outputs": [],
      "source": [
        "import scipy.linalg as la\n",
        "\n",
        "class LDA:\n",
        "\n",
        "  def __init__(self, num_features, num_dominant_vectors):\n",
        "    self.num_features = num_features\n",
        "    self.num_dominate_vectors = num_dominant_vectors\n",
        "    self.num_classes = None\n",
        "    self.projection_matrix = None\n",
        "\n",
        "  def calc_means(self, matrix):\n",
        "    means = np.zeros((self.num_classes, self.num_features))\n",
        "    num_samples = np.zeros(self.num_classes)\n",
        "\n",
        "    for i in range(1, self.num_classes):\n",
        "      means[i] = np.mean(np.array(matrix[i]), axis = 0)\n",
        "      num_samples[i] = len(matrix[i])\n",
        "\n",
        "    overall_mean = np.mean(means[1:], axis = 0)\n",
        "    return means, overall_mean, num_samples\n",
        "\n",
        "  def calc_between_class_matrix(self, num_samples, classes_means, overall_mean):\n",
        "    between_class_matrix = np.zeros((self.num_features,self.num_features))\n",
        "\n",
        "    for i in range(1, self.num_classes):\n",
        "      x = np.array(classes_means[i])\n",
        "      diff_matrix = x - overall_mean\n",
        "      c = num_samples[i] * np.outer(diff_matrix, diff_matrix)\n",
        "      between_class_matrix += c\n",
        "\n",
        "    return between_class_matrix\n",
        "\n",
        "  def calc_within_class_matrix(self, matrix, classes_means):\n",
        "    within_class_matrix = np.zeros((self.num_features, self.num_features))\n",
        "\n",
        "    for i in range(1, self.num_classes):\n",
        "      class_data = np.array(np.array(matrix[i]) - np.array(classes_means[i]))\n",
        "      scatter_matrix = np.dot((class_data).T, class_data)\n",
        "      within_class_matrix += scatter_matrix\n",
        "\n",
        "    return within_class_matrix\n",
        "\n",
        "  def fit(self, matrix):\n",
        "\n",
        "    # set number of classes of the dataset\n",
        "    self.num_classes = len(matrix)\n",
        "\n",
        "    # calculate the means vector for each class\n",
        "    classes_means, overall_mean, num_samples = self.calc_means(matrix)\n",
        "\n",
        "    # calculate the between-class scatter matrix\n",
        "    between_class_matrix = self.calc_between_class_matrix(num_samples, classes_means, overall_mean)\n",
        "\n",
        "    # calculate the within-class scatter matrix\n",
        "    within_class_matrix = self.calc_within_class_matrix(matrix, classes_means)\n",
        "\n",
        "    # calculate eigenvalues and eigenvectors\n",
        "    eigenvalues, eigenvectors = la.eig(la.pinv(within_class_matrix).dot(between_class_matrix))\n",
        "\n",
        "    # eigenvectors without complex part\n",
        "    eigenvectors = np.real(eigenvectors)\n",
        "\n",
        "    # sort eigenvalues and eigenvectors\n",
        "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
        "\n",
        "    # set the projection matrix\n",
        "    self.projection_matrix = eigenvectors[:, sorted_indices[:self.num_dominate_vectors]]\n",
        "\n",
        "  def tranform(self, matrix):\n",
        "    self.new_matrix = []\n",
        "    for i in range(len(matrix)):\n",
        "      if(matrix[i] is None):\n",
        "        continue\n",
        "      class_data = np.array(matrix[i])\n",
        "      for j in range(len(class_data)):\n",
        "        x = np.dot(class_data[j], self.projection_matrix)\n",
        "        self.new_matrix.append(x)\n",
        "\n",
        "\n",
        "  def predict(self, new_matrix_labels, X_test, X_labels, num_neigbours):\n",
        "    # Create a KNN classifier (you can adjust the 'n_neighbors' parameter)\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=num_neigbours)\n",
        "\n",
        "    # Train the classifier on the training data\n",
        "    knn_classifier.fit(self.new_matrix, new_matrix_labels)\n",
        "\n",
        "    # project test data\n",
        "    test = []\n",
        "    for i in range(len(X_test)):\n",
        "      class_data = np.array(X_test[i])\n",
        "      c = np.dot(class_data, self.projection_matrix)\n",
        "      test.append(c)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = knn_classifier.predict(test)\n",
        "\n",
        "    # Evaluate the performance of the classifier\n",
        "    accuracy = accuracy_score(X_labels, predictions)\n",
        "\n",
        "    return predictions, accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkIBxUexaElo"
      },
      "source": [
        "# <font color='orange' size='7px'> ***Basic algorithms driver Code***</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6ddoYtLqLz6"
      },
      "source": [
        "## *PCA Basic version Runner*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuHnhzy-YCeP"
      },
      "outputs": [],
      "source": [
        "def convert_lsit_to_nparray(train_ratio, path=\"/content/g\"):\n",
        "  dataMatrix, labels = loadDataset(path)\n",
        "  training_data, trainig_labels, testing_data, testing_labels = split_dataset(dataMatrix, labels, train_ratio)\n",
        "\n",
        "  x = []\n",
        "  for image in training_data:\n",
        "    for row in image:\n",
        "      x.append(row)\n",
        "\n",
        "  training_data = np.array(x)\n",
        "\n",
        "  y = []\n",
        "  for image in testing_data:\n",
        "    for row in image:\n",
        "      y.append(row)\n",
        "  testing_data = np.array(y)\n",
        "  testing_data = testing_data.reshape(int((1-train_ratio) * numberOfImages), int(numberOfFeatures / 4))\n",
        "\n",
        "  trainig_labels = np.array(trainig_labels)\n",
        "  testing_labels = np.array(testing_labels)\n",
        "\n",
        "  return training_data, trainig_labels, testing_data, testing_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac8fIswkZSYW"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def pca(train_ratio, path=\"/content/g\", k=1):\n",
        "  training_data, trainig_labels, testing_data, testing_labels = convert_lsit_to_nparray(train_ratio, path)\n",
        "  prev_time = time.time()  # Record the starting time\n",
        "  sorted_eigen_values, sorted_eigen_vectors = calc_eig_vector(training_data)\n",
        "  current_time = time.time()  # Record the current time\n",
        "  pca_time = current_time - prev_time  # Calculate execution time\n",
        "  alphas = [0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95]\n",
        "  for alpha in alphas:\n",
        "    print(f\"PCA with alpha = {alpha}\")\n",
        "    prev_time = time.time()  # Record the starting time\n",
        "    new_basis = reduce_dimentions(sorted_eigen_values, sorted_eigen_vectors, alpha)\n",
        "    new_training_data, new_testinig_data = project_all_data(new_basis, training_data, testing_data)\n",
        "    accuracy, report, incorrect_indices = cluster(new_training_data, trainig_labels, new_testinig_data, testing_labels, k)\n",
        "    current_time = time.time()  # Record the current time\n",
        "    execution_time = current_time - prev_time  # Calculate execution time\n",
        "    print(f\"Execution time for alpha {alpha}: {execution_time + pca_time} seconds\")\n",
        "    print(f\"Accuracy = {accuracy}\")\n",
        "    # print(f\"Report is\")\n",
        "    # print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHTmBTDPn21X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0bbeafb-2cfd-4522-d497-18d186a2c641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA with alpha = 0.5\n",
            "(200,) (200,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 15, 18, 31, 34, 35, 36, 37, 45, 58, 75, 78, 81, 90, 91, 97, 98, 99, 100, 111, 114, 127, 130, 131, 133, 139, 142, 144, 146, 147, 149, 151, 153, 154, 155, 157, 170, 171, 172, 173, 174, 178, 182, 185, 188, 189]\n",
            "Execution time for alpha 0.5: 6.122479438781738 seconds\n",
            "Accuracy = 0.77\n",
            "PCA with alpha = 0.6\n",
            "(200,) (200,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 18, 31, 45, 75, 78, 87, 90, 91, 100, 111, 114, 130, 133, 134, 139, 144, 151, 153, 154, 164, 170, 171, 172, 173, 174, 176, 178, 182, 185, 187, 188, 189, 194, 195, 199]\n",
            "Execution time for alpha 0.6: 6.117707967758179 seconds\n",
            "Accuracy = 0.82\n",
            "PCA with alpha = 0.7\n",
            "(200,) (200,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 45, 75, 78, 97, 98, 111, 114, 139, 170, 171, 172, 174, 195]\n",
            "Execution time for alpha 0.7: 6.115548133850098 seconds\n",
            "Accuracy = 0.93\n",
            "PCA with alpha = 0.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200,) (200,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 75, 78, 97, 98, 139, 170, 171, 172, 174, 199]\n",
            "Execution time for alpha 0.8: 6.232375860214233 seconds\n",
            "Accuracy = 0.945\n",
            "PCA with alpha = 0.85\n",
            "(200,) (200,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 75, 78, 98, 139, 170, 171, 172, 174, 199]\n",
            "Execution time for alpha 0.85: 6.210130453109741 seconds\n",
            "Accuracy = 0.95\n",
            "PCA with alpha = 0.9\n",
            "(200,) (200,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 75, 78, 98, 139, 170, 171, 172, 174, 199]\n",
            "Execution time for alpha 0.9: 6.11403751373291 seconds\n",
            "Accuracy = 0.95\n",
            "PCA with alpha = 0.95\n",
            "(200,) (200,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 75, 78, 139, 170, 171, 172, 174, 198, 199]\n",
            "Execution time for alpha 0.95: 6.1181700229644775 seconds\n",
            "Accuracy = 0.95\n"
          ]
        }
      ],
      "source": [
        "pca(0.5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca(train_ratio=0.5,k=7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX0RmY9jCgKu",
        "outputId": "cf54cdb2-ddea-4b91-8242-3734868e59a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA with alpha = 0.5\n",
            "(200,) (200,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 1, 2, 3, 10, 12, 13, 15, 18, 19, 20, 21, 22, 24, 31, 35, 36, 37, 42, 45, 46, 52, 55, 58, 59, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 87, 93, 95, 97, 98, 99, 110, 111, 114, 123, 124, 127, 129, 130, 131, 132, 133, 134, 135, 138, 139, 143, 146, 147, 149, 150, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 187, 188, 189, 197]\n",
            "Execution time for alpha 0.5: 7.121819496154785 seconds\n",
            "Accuracy = 0.525\n",
            "PCA with alpha = 0.6\n",
            "(200,) (200,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 15, 16, 19, 21, 31, 35, 36, 37, 40, 45, 46, 52, 55, 56, 57, 58, 59, 70, 72, 73, 74, 75, 77, 78, 80, 81, 82, 87, 95, 96, 97, 99, 101, 110, 111, 112, 113, 114, 120, 122, 129, 131, 132, 133, 134, 135, 138, 139, 143, 144, 150, 151, 153, 154, 155, 156, 157, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 187, 188, 189, 197]\n",
            "Execution time for alpha 0.6: 7.118130683898926 seconds\n",
            "Accuracy = 0.615\n",
            "PCA with alpha = 0.7\n",
            "(200,) (200,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 15, 19, 21, 45, 57, 59, 70, 72, 73, 74, 75, 77, 78, 80, 81, 82, 83, 84, 87, 99, 110, 111, 119, 122, 126, 131, 132, 133, 134, 135, 136, 137, 138, 139, 142, 143, 150, 153, 154, 156, 157, 162, 170, 171, 172, 173, 174, 175, 176, 177, 181, 182, 183, 184, 187, 191, 197, 198, 199]\n",
            "Execution time for alpha 0.7: 7.125015735626221 seconds\n",
            "Accuracy = 0.7\n",
            "PCA with alpha = 0.8\n",
            "(200,) (200,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 1, 15, 19, 55, 59, 70, 72, 73, 75, 77, 80, 81, 82, 95, 96, 98, 99, 110, 131, 135, 136, 138, 139, 143, 150, 153, 154, 156, 163, 170, 171, 172, 173, 174, 175, 177, 179, 181, 182, 183, 184, 195, 197, 198, 199]\n",
            "Execution time for alpha 0.8: 7.123006820678711 seconds\n",
            "Accuracy = 0.77\n",
            "PCA with alpha = 0.85\n",
            "(200,) (200,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 1, 59, 70, 72, 73, 77, 80, 81, 82, 96, 98, 110, 131, 135, 136, 137, 138, 139, 143, 150, 153, 154, 156, 157, 163, 169, 170, 171, 172, 173, 174, 175, 177, 179, 181, 182, 183, 184, 197, 198, 199]\n",
            "Execution time for alpha 0.85: 7.116875648498535 seconds\n",
            "Accuracy = 0.79\n",
            "PCA with alpha = 0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200,) (200,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 1, 59, 70, 72, 73, 77, 80, 81, 82, 96, 98, 110, 131, 135, 136, 137, 138, 139, 143, 150, 153, 154, 156, 157, 162, 163, 169, 170, 171, 172, 173, 174, 175, 177, 179, 181, 182, 183, 184, 197, 198, 199]\n",
            "Execution time for alpha 0.9: 7.136718273162842 seconds\n",
            "Accuracy = 0.785\n",
            "PCA with alpha = 0.95\n",
            "(200,) (200,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 1, 59, 70, 72, 73, 77, 80, 81, 82, 98, 110, 111, 131, 135, 136, 137, 138, 139, 143, 150, 153, 154, 156, 157, 162, 163, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 181, 182, 183, 184, 197, 198]\n",
            "Execution time for alpha 0.95: 7.211335897445679 seconds\n",
            "Accuracy = 0.785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsfCSkbhaKyo"
      },
      "source": [
        "## *LDA Basic version Runner*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sL7NiCAaRTw"
      },
      "outputs": [],
      "source": [
        "# prompt: test loaded data\n",
        "import time\n",
        "\n",
        "def Lda(train_ratio, num_neighbors):\n",
        "  # Load the dataset\n",
        "  dataMatrix, labels = loadDataset(\"/content/g\")\n",
        "  new_mat, new_labels, test_images, test_labels = split_dataset(dataMatrix, labels, train_ratio)\n",
        "  prev_time = time.time()  # Record the starting time\n",
        "  test_LDA = LDA(int(numberOfFeatures/4), 39)\n",
        "  test_LDA.fit(new_mat)\n",
        "  test_LDA.tranform(new_mat)\n",
        "  predictions, accuracy = test_LDA.predict(new_labels, test_images, test_labels, num_neighbors)\n",
        "  current_time = time.time()  # Record the current time\n",
        "  execution_time = current_time - prev_time  # Calculate execution time\n",
        "  print(f\"Accuracy: {accuracy:.2f}\")\n",
        "  print(f\"Execution time: {execution_time} seconds\")\n",
        "  # You can also print a classification report for more detailed metrics\n",
        "  # print(\"Classification Report:\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Lda(0.5, 1)\n",
        "Lda(0.5, 3)\n",
        "Lda(0.5, 5)\n",
        "Lda(0.5, 7)\n",
        "Lda(0.5, 11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz0g6CZJfOVj",
        "outputId": "386fced5-a4ae-4206-95e8-0aa35cba3dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.97\n",
            "Execution time: 43.94591021537781 seconds\n",
            "Accuracy: 0.96\n",
            "Execution time: 43.52052640914917 seconds\n",
            "Accuracy: 0.96\n",
            "Execution time: 44.77238917350769 seconds\n",
            "Accuracy: 0.96\n",
            "Execution time: 43.85331916809082 seconds\n",
            "Accuracy: 0.93\n",
            "Execution time: 44.999974489212036 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piNnqn2lThwL"
      },
      "source": [
        "# <font color='orange' size='7px'> ***Face vs non-face***</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVKhWMGH3ir7"
      },
      "source": [
        "## Convert png images to pgm and read them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-Yx1Lfr2eC_"
      },
      "outputs": [],
      "source": [
        "def jpg_to_pgm(jpg_path, pgm_path):\n",
        "  \"\"\"\n",
        "  Converts a JPG image to a PGM image using NumPy and Pillow.\n",
        "\n",
        "  Args:\n",
        "      jpg_path (str): Path to the JPG image.\n",
        "      pgm_path (str): Path to save the PGM image.\n",
        "  \"\"\"\n",
        "  # Open the JPG image with Pillow and convert to grayscale\n",
        "  img = Image.open(jpg_path).convert('L')\n",
        "\n",
        "  resized_img = img.resize((ImageWidth, ImageHeight), resample=Image.ANTIALIAS)\n",
        "\n",
        "  # Get image data as a NumPy array\n",
        "  resized_data = np.array(img)\n",
        "\n",
        "  # Prepare PGM header (assuming maximum grayscale value is 255)\n",
        "  header = f\"P5\\n{ImageWidth} {ImageHeight}\\n255\\n\"\n",
        "\n",
        "  # Save the PGM image\n",
        "  with open(pgm_path, 'wb') as f:\n",
        "    f.write(header.encode(\"utf-8\"))\n",
        "    f.write(resized_data.flatten())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSjtVTrv3BCX"
      },
      "outputs": [],
      "source": [
        "def convert_folder_jpg_to_pgm():\n",
        "  abs_path = \"/content/landscape Images/gray/\"\n",
        "  count = 0\n",
        "  for dirname, _, filenames in os.walk(abs_path):\n",
        "      for filename in sorted(filenames):\n",
        "\n",
        "        new_file_name, file_extension = os.path.splitext(filename)\n",
        "        if file_extension != \".jpg\":\n",
        "          continue\n",
        "        count = count + 1\n",
        "        if count == 401:\n",
        "          return\n",
        "        jpg_to_pgm(abs_path + filename, \"/content/s0/s0/\"  + new_file_name+\".pgm\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP80fb286clV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1be46c58-dfd4-4954-89d2-3df0aa87acde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-069d4e4c6ce9>:12: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  resized_img = img.resize((ImageWidth, ImageHeight), resample=Image.ANTIALIAS)\n"
          ]
        }
      ],
      "source": [
        "convert_folder_jpg_to_pgm()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdpaa3VIEVQ7"
      },
      "source": [
        "## PCA for Non-face vs Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KriY3sKw9aoL"
      },
      "outputs": [],
      "source": [
        "def pca_face_vs_non_face(training_data, trainig_labels, testing_data, testing_labels):\n",
        "  sorted_eigen_values, sorted_eigen_vectors = calc_eig_vector(training_data)\n",
        "  new_basis = reduce_dimentions(sorted_eigen_values, sorted_eigen_vectors, 0.8)\n",
        "  new_training_data, new_testinig_data = project_all_data(new_basis, training_data, testing_data)\n",
        "  accuracy, report, incorrect_indices = cluster(new_training_data, trainig_labels, new_testinig_data, testing_labels)\n",
        "  print(f\"Accuracy = {accuracy}\")\n",
        "  # for incorrect_index in incorrect_indices:\n",
        "  #   plot_image(testing_data[incorrect_index], resized=True)\n",
        "  # print(f\"Report is\")\n",
        "  # print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QiXuP6FRU7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd74e145-a037-44f0-8a61-49fc7e00ad5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280\n",
            "Number of non-face images = 84 and number of faces = 280\n",
            "(240,) (240,)\n",
            "Indices of incorrect predictions:\n",
            "[179, 223]\n",
            "Accuracy = 0.9916666666666667\n",
            "Number of non-face images = 140 and number of faces = 280\n",
            "(240,) (240,)\n",
            "Indices of incorrect predictions:\n",
            "[]\n",
            "Accuracy = 1.0\n",
            "Number of non-face images = 196 and number of faces = 280\n",
            "(240,) (240,)\n",
            "Indices of incorrect predictions:\n",
            "[]\n",
            "Accuracy = 1.0\n",
            "Number of non-face images = 280 and number of faces = 280\n",
            "(240,) (240,)\n",
            "Indices of incorrect predictions:\n",
            "[]\n",
            "Accuracy = 1.0\n"
          ]
        }
      ],
      "source": [
        "# read faces dataset\n",
        "face_training, face_training_labels, face_testing, face_testing_labels = convert_lsit_to_nparray(0.7)\n",
        "face_training_labels = np.ones(face_training_labels.shape[0])\n",
        "face_testing_labels = np.ones(face_testing_labels.shape[0])\n",
        "\n",
        "# read non-face dataset\n",
        "non_face_training, non_face_training_labels, non_face_testing, non_face_testing_labels = convert_lsit_to_nparray(0.7, \"/content/s0/\")\n",
        "print(len(non_face_training))\n",
        "non_face_training_labels = np.zeros(non_face_training_labels.shape[0])\n",
        "non_face_testing_labels = np.zeros(non_face_testing_labels.shape[0])\n",
        "\n",
        "# form a testing dataset from both calsses !!!!!!! will not change\n",
        "testing_data = np.concatenate((face_testing, non_face_testing), axis=0)\n",
        "testing_labels = np.concatenate((face_testing_labels, non_face_testing_labels), axis=0)\n",
        "\n",
        "non_face_pool_size =  non_face_training.shape[0]\n",
        "\n",
        "non_face_ratios = np.array([0.3,0.5, 0.7, 1])\n",
        "for non_face_ratio in non_face_ratios:\n",
        "  print(f\"Number of non-face images = {int(non_face_ratio * non_face_pool_size)} and number of faces = {face_training.shape[0]}\")\n",
        "  training_data = np.concatenate((face_training, non_face_training[:int(non_face_ratio * non_face_pool_size)]), axis=0)\n",
        "  training_labels = np.concatenate((face_training_labels, non_face_training_labels[:int(non_face_ratio * non_face_pool_size)]), axis=0)\n",
        "  pca_face_vs_non_face(training_data, training_labels, testing_data, testing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LDA for Non-face vs Face"
      ],
      "metadata": {
        "id": "_hoiN1h4nMQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lda_data_config(face_training):\n",
        "  images = []\n",
        "  labels = []\n",
        "  for i in range(len(face_training)):\n",
        "    mat = face_training[i]\n",
        "    for image in mat:\n",
        "      images.append(image)\n",
        "      labels.append(1)\n",
        "  return images, labels"
      ],
      "metadata": {
        "id": "Zj8aRG85gnKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_non_face(matrix, ratio):\n",
        "  size = len(matrix)\n",
        "  non_face_training = matrix[:int(size * ratio),:]\n",
        "  non_face_testing = matrix[int(size * ratio):,:]\n",
        "  non_face_training_labels = [2] * len(non_face_training)\n",
        "  non_face_testing_labels = [2] * len(non_face_testing)\n",
        "  return non_face_training, non_face_training_labels, non_face_testing, non_face_testing_labels\n"
      ],
      "metadata": {
        "id": "6AhAZtdyoIsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load face dataset\n",
        "data_matrix, labels = loadDataset(\"/content/g\")\n",
        "face_training, face_training_labels, face_testing, face_testing_labels = split_dataset(data_matrix, labels, 0.7)\n",
        "face_training, face_training_labels = lda_data_config(face_training)\n",
        "face_testing_labels = [1 for _ in face_testing_labels]\n",
        "\n",
        "# load non face dataset\n",
        "non_face, non_face_labels = loadDataset(\"/content/s0/\")\n",
        "print(len(non_face))\n",
        "non_face_training, non_face_training_labels, non_face_testing, non_face_testing_labels = divide_non_face(non_face, 0.7)\n",
        "\n",
        "# form a testing dataset from both calsses will not change\n",
        "testing_data = np.concatenate((face_testing, non_face_testing), axis=0)\n",
        "testing_labels = np.concatenate((face_testing_labels, non_face_testing_labels), axis=0)\n",
        "\n",
        "non_face_pool_size =  non_face_training.shape[0]\n",
        "\n",
        "non_face_ratios = np.array([0.3, 0.5, 0.7, 1])\n",
        "for non_face_ratio in non_face_ratios:\n",
        "  print(f\"Number of non-face images = {int(non_face_ratio * non_face_pool_size)} and number of faces = {len(face_training)}\")\n",
        "  training_data = [None, face_training, non_face_training[:int(non_face_ratio * non_face_pool_size)]]\n",
        "  training_labels = np.concatenate((face_training_labels, non_face_training_labels[:int(non_face_ratio * non_face_pool_size)]), axis=0)\n",
        "  test_LDA = LDA(int(numberOfFeatures / 4), 1)\n",
        "  test_LDA.fit(training_data)\n",
        "  test_LDA.tranform(training_data)\n",
        "  predictions, accuracy = test_LDA.predict(training_labels, testing_data, testing_labels, 1)\n",
        "  print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "  # You can also print a classification report for more detailed metrics\n",
        "  # print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "id": "7O3JcHXlnVky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aebce87-3a14-4287-fb8f-9c76ca9e4ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400\n",
            "Number of non-face images = 84 and number of faces = 280\n",
            "Accuracy: 0.87\n",
            "Number of non-face images = 140 and number of faces = 280\n",
            "Accuracy: 0.82\n",
            "Number of non-face images = 196 and number of faces = 280\n",
            "Accuracy: 0.84\n",
            "Number of non-face images = 280 and number of faces = 280\n",
            "Accuracy: 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIFU9cSTHbU9"
      },
      "source": [
        "# <font color='orange' size='7px'> ***Bonus***</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P-AsVyzbSgy"
      },
      "source": [
        "## Updated Training Ratio PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyvzenLnn9Z4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9732734e-7ef7-4e53-dc91-b92b5a42ca62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA with alpha = 0.5\n",
            "(120,) (120,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 9, 20, 21, 22, 48, 52, 54, 57, 59, 70, 78, 85, 86, 92, 102, 103, 104, 113]\n",
            "Execution time for alpha 0.5: 6.006243944168091 seconds\n",
            "Accuracy = 0.8416666666666667\n",
            "PCA with alpha = 0.6\n",
            "(120,) (120,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 78, 83, 102, 104, 112, 113]\n",
            "Execution time for alpha 0.6: 5.989202499389648 seconds\n",
            "Accuracy = 0.9416666666666667\n",
            "PCA with alpha = 0.7\n",
            "(120,) (120,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 83, 102, 104]\n",
            "Execution time for alpha 0.7: 5.989206552505493 seconds\n",
            "Accuracy = 0.9666666666666667\n",
            "PCA with alpha = 0.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120,) (120,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 83, 102]\n",
            "Execution time for alpha 0.8: 6.089878797531128 seconds\n",
            "Accuracy = 0.975\n",
            "PCA with alpha = 0.85\n",
            "(120,) (120,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 83, 102]\n",
            "Execution time for alpha 0.85: 5.991519212722778 seconds\n",
            "Accuracy = 0.975\n",
            "PCA with alpha = 0.9\n",
            "(120,) (120,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 83, 102]\n",
            "Execution time for alpha 0.9: 5.991412878036499 seconds\n",
            "Accuracy = 0.975\n",
            "PCA with alpha = 0.95\n",
            "(120,) (120,)\n",
            "Indices of incorrect predictions:\n",
            "[0, 83, 102]\n",
            "Execution time for alpha 0.95: 5.9933998584747314 seconds\n",
            "Accuracy = 0.975\n"
          ]
        }
      ],
      "source": [
        "pca(0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3M-TJtbgDy9"
      },
      "source": [
        "## Updated Training Ratio LDA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqmhm2RBgDzD",
        "outputId": "9fa97ea7-71b5-4fde-dc19-de4ff03680f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.99\n"
          ]
        }
      ],
      "source": [
        "Lda(0.7, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA Variation"
      ],
      "metadata": {
        "id": "Ki7X6DhB_txS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Splitting data into training and testing sets\n",
        "X_train, y_train, X_test, y_test = convert_lsit_to_nparray(0.7, \"/content/g\")\n",
        "components = [18, 28, 46, 84]\n",
        "\n",
        "for component in components:\n",
        "  # Defining a kernel PCA pipeline with a K-Nearest Neighbors classifier\n",
        "  kpca_knn_pipeline = Pipeline([\n",
        "      (\"scaler\", StandardScaler()),\n",
        "      (\"kpca\", KernelPCA(n_components=component, kernel='rbf')),  # Using RBF kernel\n",
        "      (\"knn\", KNeighborsClassifier(n_neighbors=3))  # KNN classifier\n",
        "  ])\n",
        "\n",
        "  # Training the pipeline\n",
        "  kpca_knn_pipeline.fit(X_train, y_train)\n",
        "\n",
        "  # Evaluating the pipeline\n",
        "  train_accuracy = kpca_knn_pipeline.score(X_train, y_train)\n",
        "  test_accuracy = kpca_knn_pipeline.score(X_test, y_test)\n",
        "\n",
        "  print(f\"Train Accuracy: {train_accuracy:.2f}\")\n",
        "  print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "\n",
        "# reference.1 https://www.baeldung.com/cs/intuition-behind-kernels-in-machine-learning#the-mathematics-of-kernels\n",
        "\n",
        "# reference.2 https://www.baeldung.com/cs/kernel-principal-component-analysis"
      ],
      "metadata": {
        "id": "VD2MMvSI_49q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf5e3d51-b08a-4fe1-a8d7-724a37a3c7f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.96\n",
            "Test Accuracy: 0.89\n",
            "Train Accuracy: 0.97\n",
            "Test Accuracy: 0.93\n",
            "Train Accuracy: 0.97\n",
            "Test Accuracy: 0.93\n",
            "Train Accuracy: 0.97\n",
            "Test Accuracy: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NxzBshdEK6TK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LDA Variation"
      ],
      "metadata": {
        "id": "kUlC7ili870-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "ratio = [0.5,0.7]\n",
        "for r in ratio:\n",
        "  training_data, trainig_labels, testing_data, testing_labels = convert_lsit_to_nparray(r)\n",
        "\n",
        "  fld = LinearDiscriminantAnalysis(solver='lsqr', shrinkage=0.1)\n",
        "  fld.fit(training_data, trainig_labels)\n",
        "  y_pred = fld.predict(testing_data)\n",
        "  acc = accuracy_score(testing_labels, y_pred)\n",
        "\n",
        "  print(f\"With split ratio = {r} Accuracy: {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ixTzj77871I",
        "outputId": "f2a32ce3-9a4c-4c28-a50a-f21fb7c5da62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With split ratio = 0.5 Accuracy: 0.96\n",
            "With split ratio = 0.7 Accuracy: 0.9916666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "efp1famAaklg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ygqMuuXcKsx3",
        "dDxI3gRmLAcu",
        "r1ZhUDinLRKv",
        "HYQcuv3KLCTx",
        "eof9VBz0KXKH",
        "iQAB-SBLL5QG",
        "UVKhWMGH3ir7",
        "eIFU9cSTHbU9",
        "8P-AsVyzbSgy",
        "f3M-TJtbgDy9",
        "Ki7X6DhB_txS",
        "kUlC7ili870-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}